# ğŸ”¬ Sistema de VisÃ£o Computacional DX

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)
![PyQt5](https://img.shields.io/badge/PyQt5-5.15+-red.svg)
![License](https://img.shields.io/badge/License-Proprietary-yellow.svg)
![Status](https://img.shields.io/badge/Status-Production-brightgreen.svg)

**Sistema avanÃ§ado de inspeÃ§Ã£o visual automatizada para controle de qualidade industrial**

*Desenvolvido pela equipe DX (Desenvolvimento Digital)*

</div>

---

## ğŸ“‹ Ãndice

- [ğŸ¯ VisÃ£o Geral](#-visÃ£o-geral)
- [âœ¨ Funcionalidades Principais](#-funcionalidades-principais)
- [ğŸ§® Algoritmos MatemÃ¡ticos](#-algoritmos-matemÃ¡ticos)
- [âš™ï¸ Requisitos do Sistema](#ï¸-requisitos-do-sistema)
- [ğŸš€ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ğŸ“Š Arquitetura do Sistema](#-arquitetura-do-sistema)
- [ğŸ”§ ConfiguraÃ§Ã£o e Uso](#-configuraÃ§Ã£o-e-uso)
- [ğŸ“ˆ Performance e OtimizaÃ§Ã£o](#-performance-e-otimizaÃ§Ã£o)
- [ğŸ› ï¸ Desenvolvimento](#ï¸-desenvolvimento)
- [ğŸ“ Suporte](#-suporte)

---

## ğŸ¯ VisÃ£o Geral

O **Sistema de VisÃ£o Computacional DX** Ã© uma soluÃ§Ã£o completa de inspeÃ§Ã£o visual automatizada que combina tÃ©cnicas avanÃ§adas de **visÃ£o computacional**, **machine learning** e **processamento de imagens** para realizar controle de qualidade industrial com alta precisÃ£o e eficiÃªncia.

### ğŸ—ï¸ Arquitetura Modular

```mermaid
graph TB
    A[Dashboard Principal] --> B[MÃ³dulo de Montagem]
    A --> C[Gerenciador de BD]
    A --> D[Seletor de Modelos]
    B --> E[Template Matching]
    B --> F[Feature Detection]
    B --> G[Machine Learning]
    B --> H[AnÃ¡lise de Histogramas]
```

## âœ¨ Funcionalidades Principais

### ğŸ” **MÃ³dulo de Montagem AvanÃ§ado**
- âœ… **VerificaÃ§Ã£o automÃ¡tica** de montagem de componentes
- ğŸ¯ **Template matching** com mÃºltiplos algoritmos
- ğŸ¤– **Sistema de treinamento** com amostras OK/NG
- ğŸ“ **DetecÃ§Ã£o de alinhamento** e posicionamento
- ğŸ“¹ **Suporte a mÃºltiplas cÃ¢meras** (USB, Industrial)
- âš™ï¸ **Interface de configuraÃ§Ã£o** avanÃ§ada
- ğŸ“Š **RelatÃ³rios em tempo real** com mÃ©tricas detalhadas

### ğŸ§  **InteligÃªncia Artificial Integrada**
- ğŸŒ² **Random Forest Classifier** para classificaÃ§Ã£o OK/NG
- ğŸ¯ **Support Vector Machine (SVM)** para casos complexos
- ğŸ“ˆ **ValidaÃ§Ã£o cruzada** automÃ¡tica
- ğŸ”„ **Retreinamento** de slots especÃ­ficos
- ğŸ“Š **MÃ©tricas de performance** em tempo real

### ğŸ¨ **Interface Moderna e Intuitiva**
- ğŸ–¥ï¸ **Dashboard centralizado** com PyQt5
- ğŸ¨ **Interface moderna** com ttkbootstrap
- ğŸ“± **Design responsivo** e adaptÃ¡vel
- ğŸ”§ **ConfiguraÃ§Ã£o visual** de parÃ¢metros
- ğŸ“Š **VisualizaÃ§Ã£o em tempo real** dos resultados

## ğŸ§® Algoritmos MatemÃ¡ticos

### ğŸ“ **Template Matching**

O sistema utiliza correlaÃ§Ã£o cruzada normalizada para detectar componentes:

**FÃ³rmula da CorrelaÃ§Ã£o Cruzada Normalizada:**

```
Î³(u,v) = Î£[T(x,y) - TÌ„][I(x+u,y+v) - Äª(u,v)] / âˆš{Î£[T(x,y) - TÌ„]Â² Â· Î£[I(x+u,y+v) - Äª(u,v)]Â²}
```

Onde:
- `T(x,y)` = Template de referÃªncia
- `I(x,y)` = Imagem de entrada
- `TÌ„` = MÃ©dia do template
- `Äª(u,v)` = MÃ©dia da regiÃ£o da imagem
- `Î³(u,v)` = Coeficiente de correlaÃ§Ã£o (-1 â‰¤ Î³ â‰¤ 1)

**ImplementaÃ§Ã£o OpenCV:**
```python
result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)
locations = np.where(result >= threshold)  # threshold âˆˆ [0.7, 0.95]
```

### ğŸ¯ **Feature Detection (ORB)**

**Algoritmo FAST (Features from Accelerated Segment Test):**

Para um pixel `p` com intensidade `Ip`, um ponto Ã© considerado corner se:

```
âˆƒ conjunto S de n pixels contÃ­guos no cÃ­rculo de 16 pixels tal que:
âˆ€ pixel x âˆˆ S: |Ix - Ip| > t
```

Onde `t` Ã© o threshold de intensidade e `n â‰¥ 12` para FAST-12.

**Descritor BRIEF:**

Para um patch de imagem suavizada `S`, o descritor binÃ¡rio Ã©:

```
Ï„(S; x, y) = { 1 se S(x) < S(y)
             { 0 caso contrÃ¡rio
```

**ParÃ¢metros ORB Otimizados:**
```python
orb = cv2.ORB_create(
    nfeatures=500,        # MÃ¡ximo de features
    scaleFactor=1.2,      # Fator de escala da pirÃ¢mide
    nlevels=8,            # NÃ­veis da pirÃ¢mide
    edgeThreshold=31,     # Tamanho da borda
    firstLevel=0,         # Primeiro nÃ­vel da pirÃ¢mide
    WTA_K=2,              # Pontos para produzir elementos BRIEF
    scoreType=cv2.ORB_HARRIS_SCORE,
    patchSize=31,         # Tamanho do patch para descritor
    fastThreshold=20      # Threshold FAST
)
```

### ğŸ”„ **RANSAC (Random Sample Consensus)**

**Algoritmo para Estimativa de Homografia:**

1. **SeleÃ§Ã£o AleatÃ³ria:** Escolher 4 pontos correspondentes aleatoriamente
2. **Modelo:** Calcular homografia `H` usando DLT (Direct Linear Transform)
3. **Consenso:** Contar inliers usando distÃ¢ncia de reprojeÃ§Ã£o:

```
d = ||x'i - HÂ·xi|| < threshold
```

4. **IteraÃ§Ã£o:** Repetir N vezes onde:

```
N = log(1-p) / log(1-(1-Îµ)^s)
```

Onde:
- `p` = probabilidade de sucesso (0.99)
- `Îµ` = proporÃ§Ã£o de outliers
- `s` = nÃºmero mÃ­nimo de pontos (4)

**ImplementaÃ§Ã£o:**
```python
H, mask = cv2.findHomography(
    src_pts, dst_pts, 
    cv2.RANSAC, 
    ransacReprojThreshold=5.0,
    maxIters=2000,
    confidence=0.995
)
```

### ğŸ“Š **AnÃ¡lise de Histogramas**

**ComparaÃ§Ã£o de Histogramas HSV:**

**CorrelaÃ§Ã£o de Histogramas:**
```
Ï(H1,H2) = Î£[H1(i) - HÌ„1][H2(i) - HÌ„2] / âˆš{Î£[H1(i) - HÌ„1]Â² Â· Î£[H2(i) - HÌ„2]Â²}
```

**Chi-Square Distance:**
```
Ï‡Â²(H1,H2) = Î£[(H1(i) - H2(i))Â² / (H1(i) + H2(i))]
```

**Bhattacharyya Distance:**
```
dB(H1,H2) = âˆš{1 - (1/âˆš(HÌ„1Â·HÌ„2Â·NÂ²)) Â· Î£âˆš(H1(i)Â·H2(i))}
```

### ğŸ¤– **Machine Learning**

**Random Forest Classifier:**

**Entropia para DivisÃ£o de NÃ³s:**
```
H(S) = -Î£(pi Â· log2(pi))
```

**Information Gain:**
```
IG(S,A) = H(S) - Î£(|Sv|/|S| Â· H(Sv))
```

**Support Vector Machine:**

**FunÃ§Ã£o de DecisÃ£o:**
```
f(x) = sign(Î£(Î±iÂ·yiÂ·K(xi,x)) + b)
```

**Kernel RBF:**
```
K(xi,xj) = exp(-Î³||xi - xj||Â²)
```

### ğŸ“ˆ **MÃ©tricas de AvaliaÃ§Ã£o**

**AcurÃ¡cia:**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**PrecisÃ£o:**
```
Precision = TP / (TP + FP)
```

**Recall (Sensibilidade):**
```
Recall = TP / (TP + FN)
```

**F1-Score:**
```
F1 = 2 Â· (Precision Â· Recall) / (Precision + Recall)
```

**ValidaÃ§Ã£o Cruzada K-Fold:**
```
CV_Score = (1/k) Â· Î£(Accuracy_i)
```

---

## ğŸ“Š Diagramas e Fluxogramas

### ğŸ”„ **Fluxo de Processamento Principal**

```mermaid
flowchart TD
    A[ğŸ“· Captura de Imagem] --> B{ğŸ” PrÃ©-processamento}
    B --> C[ğŸ“ Template Matching]
    B --> D[ğŸ¯ Feature Detection]
    B --> E[ğŸ“Š AnÃ¡lise de Histograma]
    
    C --> F{ğŸ¯ Threshold OK?}
    D --> G{ğŸ”— Matches Suficientes?}
    E --> H{ğŸ“ˆ Similaridade OK?}
    
    F -->|Sim| I[âœ… Componente OK]
    F -->|NÃ£o| J[âŒ Componente NG]
    G -->|Sim| I
    G -->|NÃ£o| J
    H -->|Sim| I
    H -->|NÃ£o| J
    
    I --> K[ğŸ¤– ML Validation]
    J --> K
    K --> L[ğŸ“‹ Resultado Final]
    L --> M[ğŸ’¾ Salvar Log]
    M --> N[ğŸ“Š Atualizar Dashboard]
```

### ğŸ§  **Pipeline de Machine Learning**

```mermaid
flowchart LR
    A[ğŸ“¸ Amostras OK/NG] --> B[ğŸ”§ Feature Extraction]
    B --> C[ğŸ“Š NormalizaÃ§Ã£o]
    C --> D{ğŸŒ³ Algoritmo}
    
    D -->|Random Forest| E[ğŸŒ² RF Classifier]
    D -->|SVM| F[ğŸ¯ SVM Classifier]
    
    E --> G[ğŸ“ˆ Cross Validation]
    F --> G
    G --> H[ğŸ¯ OtimizaÃ§Ã£o HiperparÃ¢metros]
    H --> I[ğŸ’¾ Modelo Treinado]
    I --> J[ğŸ” PrediÃ§Ã£o]
    J --> K[ğŸ“Š MÃ©tricas]
```

### ğŸ¯ **Arquitetura do Sistema de DetecÃ§Ã£o**

```mermaid
graph TB
    subgraph "ğŸ–¥ï¸ Interface Principal"
        A[Dashboard] --> B[Seletor de Modelos]
        B --> C[ConfiguraÃ§Ãµes]
    end
    
    subgraph "ğŸ“· MÃ³dulo de Captura"
        D[Camera Manager] --> E[Image Preprocessor]
        E --> F[Quality Check]
    end
    
    subgraph "ğŸ” MÃ³dulo de DetecÃ§Ã£o"
        G[Template Matching] --> J[Fusion Engine]
        H[ORB + RANSAC] --> J
        I[Histogram Analysis] --> J
        J --> K[ML Classifier]
    end
    
    subgraph "ğŸ’¾ PersistÃªncia"
        L[(SQLite DB)] --> M[Model Storage]
        M --> N[Training Data]
    end
    
    F --> G
    F --> H
    F --> I
    K --> L
    C --> L
```

### ğŸ“ˆ **Processo de Treinamento**

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ UsuÃ¡rio
    participant UI as ğŸ–¥ï¸ Interface
    participant ML as ğŸ¤– ML Engine
    participant DB as ğŸ’¾ Database
    
    U->>UI: Selecionar Slot
    UI->>ML: Inicializar Treinamento
    
    loop Coleta de Amostras
        U->>UI: Capturar/Carregar Imagem
        UI->>U: Classificar OK/NG
        UI->>DB: Salvar Amostra
    end
    
    U->>UI: Iniciar Treinamento
    UI->>ML: Processar Amostras
    ML->>ML: Feature Extraction
    ML->>ML: Cross Validation
    ML->>UI: Retornar MÃ©tricas
    UI->>U: Exibir Resultados
    
    alt Modelo Aprovado
        U->>UI: Salvar Modelo
        UI->>DB: Persistir Modelo
        DB->>UI: ConfirmaÃ§Ã£o
    else Retreinar
        U->>UI: Ajustar ParÃ¢metros
        Note over UI,ML: Repetir Processo
    end
```

### ğŸ”§ **ConfiguraÃ§Ã£o de ParÃ¢metros**

```mermaid
mindmap
  root((âš™ï¸ ConfiguraÃ§Ãµes))
    ğŸ¯ Template Matching
      Threshold (0.7-0.95)
      MÃ©todo (CCOEFF_NORMED)
      Multi-scale
    ğŸ” ORB Features
      nFeatures (500)
      scaleFactor (1.2)
      nLevels (8)
      edgeThreshold (31)
    ğŸ¤– Machine Learning
      Algoritmo (RF/SVM)
      Cross Validation (5-fold)
      HiperparÃ¢metros
    ğŸ“Š MÃ©tricas
      AcurÃ¡cia MÃ­nima (85%)
      PrecisÃ£o/Recall
      F1-Score
```

---

## âš™ï¸ Requisitos do Sistema

- **Python**: 3.8 ou superior
- **Sistema Operacional**: Windows 10/11, Linux, macOS
- **MemÃ³ria RAM**: MÃ­nimo 4GB (recomendado 8GB)
- **CÃ¢mera**: Webcam USB ou cÃ¢mera industrial compatÃ­vel
- **Processador**: Intel i5 ou equivalente (recomendado i7)

## InstalaÃ§Ã£o

### 1. PreparaÃ§Ã£o do Ambiente

Certifique-se de ter o Python 3.8 ou superior instalado:
```bash
python --version
```

### 2. Clone ou Baixe o Projeto
```bash
git clone https://github.com/walterrvf/DX-Project.git
cd DX-Project
```

### 3. Crie um Ambiente Virtual (Recomendado)
```bash
python -m venv venv
```

### 4. Ative o Ambiente Virtual

**Windows:**
```bash
venv\Scripts\activate
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 5. Instale as DependÃªncias
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 6. VerificaÃ§Ã£o da InstalaÃ§Ã£o
```bash
python -c "import cv2, PyQt5, ttkbootstrap; print('InstalaÃ§Ã£o bem-sucedida!')"
```

### ğŸ”— **Status do RepositÃ³rio**

âœ… **RepositÃ³rio Atualizado**: Janeiro 2025  
ğŸš€ **VersÃ£o Atual**: 2.0 - DocumentaÃ§Ã£o TÃ©cnica Completa  
ğŸ“Š **Tamanho**: 111.59 MB (216 arquivos)  

**ğŸ†• Novidades IncluÃ­das:**
- ğŸ“š DocumentaÃ§Ã£o tÃ©cnica detalhada com fundamentos matemÃ¡ticos
- ğŸ¤– Sistema de Machine Learning integrado (Random Forest + SVM)
- ğŸ”§ OtimizaÃ§Ãµes especÃ­ficas para Raspberry Pi
- ğŸ“ˆ MÃ©tricas avanÃ§adas de performance e validaÃ§Ã£o
- ğŸ¨ Interface moderna com PyQt5 e ttkbootstrap
- ğŸ” Algoritmos de visÃ£o computacional otimizados
- ğŸ“‹ RelatÃ³rios automÃ¡ticos e anÃ¡lise de dados

## Executando o Sistema

### ExecuÃ§Ã£o PadrÃ£o
1. Certifique-se de que o ambiente virtual estÃ¡ ativado
2. Execute o programa principal:
```bash
python app.py
```

### ExecuÃ§Ã£o do MÃ³dulo de Montagem
O mÃ³dulo de montagem pode ser executado independentemente para testes:
```bash
# MÃ³dulo de Montagem
python -m modulos.montagem
```

## Estrutura do Projeto

```
sistema-visao-computacional/
â”œâ”€â”€ app.py                      # Dashboard principal do sistema
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o do projeto
â”‚
â”œâ”€â”€ assets/                     # Recursos visuais
â”‚   â””â”€â”€ logo.svg               # Logo do sistema
â”‚
â”œâ”€â”€ modelos/                    # Modelos e templates
â”‚   â”œâ”€â”€ _templates/            # Templates de referÃªncia
â”‚   â”‚   â”œâ”€â”€ slot_1_template.png
â”‚   â”‚   â”œâ”€â”€ slot_2_template.png
â”‚   â”‚   â””â”€â”€ slot_3_template.png
â”‚   â”œâ”€â”€ modelo_exemplo/        # Modelos especÃ­ficos
â”‚   â””â”€â”€ models.db             # Banco de dados SQLite
â”‚
â”œâ”€â”€ modulos/                    # MÃ³dulos do sistema
â”‚   â”œâ”€â”€ __pycache__/           # Cache Python (gerado automaticamente)
â”‚   â”œâ”€â”€ database_manager.py    # Gerenciador de banco de dados
â”‚   â”œâ”€â”€ model_selector.py      # Seletor de modelos
â”‚   â”œâ”€â”€ montagem.py            # MÃ³dulo principal de verificaÃ§Ã£o de montagem
â”‚   â””â”€â”€ utils.py               # UtilitÃ¡rios e configuraÃ§Ãµes
â”‚
â””â”€â”€ Imagem de teste/           # Imagens para testes
    â”œâ”€â”€ NG.JPG                # Exemplo de imagem com defeito
    â””â”€â”€ OK.jpg                # Exemplo de imagem aprovada
```

## ConfiguraÃ§Ã£o Inicial

### ConfiguraÃ§Ã£o de CÃ¢mera
1. Conecte sua cÃ¢mera USB ou webcam
2. Execute o sistema e acesse o mÃ³dulo de Montagem
3. Use a funÃ§Ã£o "Detectar CÃ¢meras" para identificar dispositivos disponÃ­veis
4. Selecione a cÃ¢mera desejada nas configuraÃ§Ãµes

### CriaÃ§Ã£o de Modelos
1. Acesse o mÃ³dulo de Montagem
2. Clique em "Novo Modelo" e defina um nome
3. Carregue uma imagem de referÃªncia
4. Defina as Ã¡reas de inspeÃ§Ã£o (slots)
5. Treine o modelo com amostras OK e NG
6. Salve o modelo no banco de dados

## Uso do Sistema

### Dashboard Principal
O dashboard oferece acesso ao mÃ³dulo de montagem:
- **Montagem**: VerificaÃ§Ã£o de componentes montados

### MÃ³dulo de Montagem - Funcionalidades AvanÃ§adas

#### CriaÃ§Ã£o de Slots de InspeÃ§Ã£o
1. Carregue uma imagem de referÃªncia
2. Use o mouse para desenhar retÃ¢ngulos nas Ã¡reas a serem inspecionadas
3. Configure parÃ¢metros especÃ­ficos para cada slot:
   - Limiar de correlaÃ§Ã£o
   - Tipo de inspeÃ§Ã£o (presenÃ§a/ausÃªncia, cor, forma)
   - TolerÃ¢ncias

#### Sistema de Treinamento
1. Capture mÃºltiplas amostras OK (aprovadas)
2. Capture amostras NG (rejeitadas)
3. O sistema calcularÃ¡ automaticamente os limiares Ã³timos
4. Teste o modelo com novas imagens

#### InspeÃ§Ã£o em Tempo Real
1. Selecione um modelo treinado
2. Ative a captura ao vivo
3. O sistema processarÃ¡ automaticamente cada frame
4. Resultados sÃ£o exibidos em tempo real

## DependÃªncias Detalhadas

### Principais Bibliotecas
- **PyQt5**: Interface grÃ¡fica principal
- **ttkbootstrap**: Interface moderna para mÃ³dulos especÃ­ficos
- **OpenCV**: Processamento de imagem e visÃ£o computacional
- **NumPy**: OperaÃ§Ãµes matemÃ¡ticas e arrays
- **Pillow**: ManipulaÃ§Ã£o de imagens
- **SQLite3**: Banco de dados (incluÃ­do no Python)

### Algoritmos Utilizados
- **Template Matching**: DetecÃ§Ã£o de componentes
- **ORB (Oriented FAST and Rotated BRIEF)**: DetecÃ§Ã£o de features
- **RANSAC**: Estimativa robusta de transformaÃ§Ãµes
- **CorrelaÃ§Ã£o Cruzada**: AnÃ¡lise de similaridade

## Adicionando Novos MÃ³dulos

### Estrutura BÃ¡sica
Para adicionar um novo mÃ³dulo:

1. Crie um arquivo `.py` na pasta `modulos/`
2. Implemente uma classe que herde de `QMainWindow`
3. Adicione uma funÃ§Ã£o `main()` para execuÃ§Ã£o independente
4. O mÃ³dulo serÃ¡ automaticamente detectado pelo dashboard

### Exemplo de MÃ³dulo
```python
from PyQt5.QtWidgets import QMainWindow, QWidget, QVBoxLayout, QLabel
from PyQt5.QtCore import Qt

class NovoModuloWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle('Novo MÃ³dulo')
        self.setGeometry(150, 150, 600, 400)
        self.setStyleSheet('background-color: white;')
        
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        layout = QVBoxLayout(central_widget)
        
        title = QLabel('Novo MÃ³dulo')
        title.setAlignment(Qt.AlignCenter)
        title.setStyleSheet('font-size: 24px; color: #212529; margin: 20px;')
        layout.addWidget(title)

def main():
    import sys
    from PyQt5.QtWidgets import QApplication
    app = QApplication.instance()
    if app is None:
        app = QApplication(sys.argv)
    window = NovoModuloWindow()
    window.show()
    return window

if __name__ == "__main__":
    main()
```

## SoluÃ§Ã£o de Problemas

### Problemas de InstalaÃ§Ã£o

#### Erro ao instalar OpenCV
```bash
# Se houver erro com opencv-python, tente:
pip install opencv-python-headless==4.8.1.78

# Ou instale as dependÃªncias do sistema (Linux):
sudo apt-get install python3-opencv
```

#### Erro ao instalar PyQt5
```bash
# Windows - instale Visual C++ Redistributable
# Linux:
sudo apt-get install python3-pyqt5

# macOS:
brew install pyqt5
```

#### Problemas com ttkbootstrap
```bash
# Se houver conflitos, instale versÃ£o especÃ­fica:
pip install ttkbootstrap==1.10.1 --force-reinstall
```

### Problemas de ExecuÃ§Ã£o

#### Programa nÃ£o inicia
1. **Verifique as dependÃªncias:**
   ```bash
   pip list | grep -E "PyQt5|opencv|ttkbootstrap"
   ```

2. **Teste a importaÃ§Ã£o:**
   ```bash
   python -c "import PyQt5, cv2, ttkbootstrap; print('OK')"
   ```

3. **Verifique o ambiente virtual:**
   ```bash
   which python  # Linux/Mac
   where python  # Windows
   ```

#### MÃ³dulo nÃ£o aparece no dashboard
1. Verifique se o arquivo estÃ¡ em `modulos/`
2. Confirme se hÃ¡ uma funÃ§Ã£o `main()` no mÃ³dulo
3. Verifique erros de sintaxe:
   ```bash
   python -m py_compile modulos/nome_do_modulo.py
   ```

#### Problemas com cÃ¢mera
1. **CÃ¢mera nÃ£o detectada:**
   - Verifique se a cÃ¢mera estÃ¡ conectada
   - Teste com outros aplicativos
   - Execute como administrador (Windows)

2. **Erro de permissÃ£o (Linux):**
   ```bash
   sudo usermod -a -G video $USER
   # Reinicie a sessÃ£o
   ```

3. **MÃºltiplas cÃ¢meras:**
   - Use a funÃ§Ã£o "Detectar CÃ¢meras" no mÃ³dulo
   - Teste diferentes Ã­ndices (0, 1, 2...)

#### Problemas de performance
1. **Sistema lento:**
   - Reduza a resoluÃ§Ã£o da cÃ¢mera
   - Ajuste os parÃ¢metros ORB
   - Feche outros aplicativos

2. **Alto uso de CPU:**
   - Aumente o intervalo entre frames
   - Reduza o nÃºmero de features ORB
   - Use modo de inspeÃ§Ã£o por demanda

### Problemas com Banco de Dados

#### Erro ao salvar modelo
```bash
# Verifique permissÃµes da pasta
ls -la modelos/

# Recrie o banco se necessÃ¡rio
rm modelos/models.db
# O banco serÃ¡ recriado automaticamente
```

#### Modelos nÃ£o carregam
1. Verifique a integridade do banco:
   ```python
   import sqlite3
   conn = sqlite3.connect('modelos/models.db')
   cursor = conn.cursor()
   cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
   print(cursor.fetchall())
   ```

### Problemas com Imagens

#### Erro ao carregar logo
1. Verifique se `assets/logo.svg` existe
2. Teste com formato alternativo (PNG/JPG)
3. Verifique permissÃµes do arquivo

#### Imagens nÃ£o processam corretamente
1. **Formatos suportados:** JPG, PNG, BMP, TIFF
2. **Tamanho mÃ¡ximo:** Recomendado atÃ© 4K (3840x2160)
3. **Verificar codificaÃ§Ã£o:**
   ```python
   import cv2
   img = cv2.imread('caminho/para/imagem.jpg')
   print(f"Imagem carregada: {img is not None}")
   ```

### Logs e Debugging

#### Ativar modo debug
```bash
# Execute com logs detalhados
python app.py --debug

# Ou defina variÃ¡vel de ambiente
export OPENCV_LOG_LEVEL=DEBUG  # Linux/Mac
set OPENCV_LOG_LEVEL=DEBUG     # Windows
```

#### Verificar logs do sistema
- **Windows:** Event Viewer
- **Linux:** `/var/log/syslog` ou `journalctl`
- **macOS:** Console.app

### Contato e Suporte

Se os problemas persistirem:
1. Colete informaÃ§Ãµes do sistema:
   ```bash
   python --version
   pip list
   # Inclua essas informaÃ§Ãµes ao reportar problemas
   ```
2. Documente os passos para reproduzir o erro
3. Inclua screenshots ou logs de erro quando possÃ­vel

## ContribuiÃ§Ã£o

### Como Contribuir
1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

### PadrÃµes de CÃ³digo
- Use PEP 8 para formataÃ§Ã£o Python
- Adicione docstrings para funÃ§Ãµes e classes
- Inclua testes para novas funcionalidades
- Mantenha compatibilidade com Python 3.8+

### Reportando Bugs
Ao reportar bugs, inclua:
- VersÃ£o do Python e sistema operacional
- Lista de dependÃªncias (`pip list`)
- Passos para reproduzir o problema
- Screenshots ou logs de erro
- Comportamento esperado vs. atual

## Roadmap

### VersÃ£o Atual (v1.0)
- âœ… Sistema de inspeÃ§Ã£o de montagem
- âœ… Interface grÃ¡fica com PyQt5
- âœ… Banco de dados SQLite
- âœ… Template matching
- âœ… Sistema de treinamento

### PrÃ³ximas VersÃµes
- ğŸ”„ **v1.1**: Melhorias na interface do usuÃ¡rio
- ğŸ“‹ **v1.2**: RelatÃ³rios avanÃ§ados e exportaÃ§Ã£o
- ğŸ¤– **v2.0**: IntegraÃ§Ã£o com machine learning
- ğŸŒ **v2.1**: Interface web para monitoramento remoto
- ğŸ“Š **v2.2**: Dashboard de analytics em tempo real

## LicenÃ§a

Este projeto Ã© desenvolvido pela equipe DX (Desenvolvimento Digital). Todos os direitos reservados.

## CrÃ©ditos

### Desenvolvido por
- **Equipe DX (Desenvolvimento Digital)**
- **Departamento de VisÃ£o Computacional**

### Tecnologias Utilizadas
- **Python**: Linguagem principal
- **OpenCV**: Biblioteca de visÃ£o computacional
- **PyQt5**: Framework de interface grÃ¡fica
- **NumPy**: ComputaÃ§Ã£o cientÃ­fica
- **SQLite**: Banco de dados

### Agradecimentos
- Equipe de ProduÃ§Ã£o pela colaboraÃ§Ã£o nos testes
- Departamento de TI pelo suporte tÃ©cnico
- Engenheiros de Qualidade pelas especificaÃ§Ãµes tÃ©cnicas

---

**Â© 2024 Equipe DX - Desenvolvimento Digital. Todos os direitos reservados.**

*Sistema de VisÃ£o Computacional DX - VersÃ£o 1.0*
